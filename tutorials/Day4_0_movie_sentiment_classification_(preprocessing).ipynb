{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이전에 KoNLPy를 이용하여 텍스트 데이터를 토크나이징 하는 방법 + Term frequency matrix로 만들어 저장하는 방법까지 연습하였습니다. 제가 만들고 있는 soynlp를 이용해서도 토크나이징의 전처리를 할 수 있습니다. (이 패키지를 왜 쓰고 있는지는 아래 주소로 가서 튜토리얼을 읽어보세요)\n",
    "\n",
    "    https://github.com/lovit/soynlp\n",
    "\n",
    "이후 데이터에 대하여 이와 같은 전처리를 하는 방법은 디테일한 설명을 하지 않고 코드를 적어둘 예정입니다. 정리하는 목적으로, WordExtractor만 이용하여 토크나이징까지 하는 과정을 기술해 봅니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "약 50여개의 유명한 영화들에 대하여 네이버영화에서 평점과 영화평을 모은 데이터입니다. 컬럼은\n",
    "\n",
    "    <영화 아이디, 텍스트, 평점>\n",
    "    \n",
    "으로 되어 있으며 tap 구분이 되어 있습니다. 이렇게 데이터의 타입을 확인하기 위해서 \n",
    "\n",
    "    for _ in range(3):\n",
    "        print(next(f)\n",
    "        \n",
    "를 하시면 텍스트 데이터의 맨 위 3줄을 볼 수 있습니다. 포멧을 확인한 뒤, 데이터를 로딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72523\t명불허전\t1\n",
      "72523\t왠지 고사 피의중간고사보다 재미가없을듯해요 만약보게된다면실망할듯\t1\n",
      "72523\t티아라 사랑해 ㅜ\t10\n"
     ]
    }
   ],
   "source": [
    "movie_reviews = './data/merged_movie_comments.txt'\n",
    "with open(movie_reviews, encoding='utf-8') as f:\n",
    "    for _ in range(3):\n",
    "        print(next(f).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load_comments() 함수의 구조는 앞서 연습한 방법과 동일합니다. 한 가지, \n",
    "\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    \n",
    "처럼 docs = [doc for doc in docs] 를 하는 동안에 영화 아이디를 제거하고, int(doc[2])처럼 str로 되어 있는 평점을 숫자로 바꿔뒀습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_comments(fname):\n",
    "    with open(fname, encoding='utf-8') as f:\n",
    "        docs = [doc.strip().split('\\t') for doc in f]\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    texts, scores = zip(*docs)\n",
    "    return texts, scores\n",
    "\n",
    "texts, scores = load_comments(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('명불허전',\n",
       "  '왠지 고사 피의중간고사보다 재미가없을듯해요 만약보게된다면실망할듯',\n",
       "  '티아라 사랑해 ㅜ',\n",
       "  '황정음 윤시윤 지붕킥 인연 김수로 티아라지연 공부의신 인연 너무너무재미있어요',\n",
       "  '기대 완전'),\n",
       " (1, 1, 10, 10, 8))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5], scores[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soynlp.word.WordExtractor를 이용하여 cohesion score, branching entropy와 같은 word score를 학습합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training was done. used memory 4.762 Gb\n",
      "all cohesion probabilities was computed. # words = 801752\n",
      "all branching entropies was computed # words = 912377\n",
      "all accessor variety was computed # words = 912377\n"
     ]
    }
   ],
   "source": [
    "from soynlp.word import WordExtractor\n",
    "\n",
    "word_extractor = WordExtractor()\n",
    "word_extractor.train(texts)\n",
    "word_scores = word_extractor.word_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MaxScoreTokenizer에 cohesion_forward * right_branching_entropy 점수를 곱한 값을 최종 단어 점수로 여기는 tokenizer_scores dictionary를 만든 뒤, 이를 이용하여 문장을 토크나이징 합니다. \n",
    "\n",
    "주어진 데이터에 대해서 미리 토크나이징을 해두면 좋습니다. 큰 데이터는 토크나이징이 오래 걸리기 때문에 미리 전처리가 된 데이터를 만들어두면 이후의 작업이 효율적입니다. 우리의 연습의 경우, 아래의 raw 파일이 다음처럼 토크나이징 되어 저장되어 있습니다. \n",
    "\n",
    "    raw file: '.data/merged_movie_comments.txt'\n",
    "    \n",
    "    tokenized file: './data/merged_movie_comments_tsoynlp.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['왠지',\n",
       " '고사',\n",
       " '피의',\n",
       " '중간',\n",
       " '고사',\n",
       " '보다',\n",
       " '재미',\n",
       " '가',\n",
       " '없을',\n",
       " '듯해요',\n",
       " '만약',\n",
       " '보게',\n",
       " '된다',\n",
       " '면',\n",
       " '실망',\n",
       " '할듯']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "\n",
    "tokenizer_scores = {word:score.cohesion_forward * score.right_branching_entropy \n",
    "                    for word, score in word_scores.items()}\n",
    "tokenizer = MaxScoreTokenizer(scores = tokenizer_scores)\n",
    "tokenizer.tokenize('왠지 고사 피의중간고사보다 재미가없을듯해요 만약보게된다면실망할듯')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
