{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 시간, Day4_1_word2vec_and_doc2vec_moviereview.ipynb에서 영화 리뷰를 이용하여 172개의 영화의 임베딩 백터를 구하였습니다. 이 벡터를 이용하여 리뷰가 비슷한 영화들을 군집화 해보겠습니다. \n",
    "\n",
    "{영화 id: 영화 이름} dict와 pickling을 한 doc2vec model을 loading 하겠습니다. 이전 시간의 모델을 이용하기 때문에 이번 day5_1의 gensim version 역시 0.13.x입니다. version 1.0.1은 이후에 올려드리겠습니다. (이 튜토리얼을 만들고나서 또 gensim version이 2.x로 올랐습니다. 2.x로 만들어드리겠습니다)\n",
    "\n",
    "id2movie의 형태는 아래와 같습니다. \n",
    "\n",
    "    {'98896': '교통신호',\n",
    "     '75104': 'To',\n",
    "     '22938': '제3공작',\n",
    "     '28840': '허리케인 카터',\n",
    "     '22757': '임 그리워',\n",
    "     ...\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../../../data/sample_naver_movie/movie_review_doc2vec_model_v2.2.pkl', 'rb') as f:\n",
    "    doc2vec_model = pickle.load(f)\n",
    "    \n",
    "with open('../../../data/sample_naver_movie/navermovie_info_idx2moviename.pkl', 'rb') as f:\n",
    "    id2movie = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec에서 document (영화)의 임베딩 차원은 300이며, 영화의 개수는 172개임을 확인할 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2vec_model.docvecs.doctag_syn0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "172개의 각 row에 해당하는 영화가 무엇인지 제목을 미리 list로 만들어 두겠습니다. 각 row id에 해당하는 label이 dict 형태로, Doc2Vec.docvecs.doctags에 저장되어 있습니다. \n",
    "\n",
    "    > doc2vec_model.docvecs.doctags\n",
    "    \n",
    "    {'MOVIE_100647': Doctag(offset=153, word_count=300107, doc_count=20577),\n",
    "     'MOVIE_100691': Doctag(offset=155, word_count=310711, doc_count=19777),\n",
    "     'MOVIE_100931': Doctag(offset=28, word_count=548150, doc_count=36068),\n",
    "     'MOVIE_102272': Doctag(offset=84, word_count=580131, doc_count=33614),\n",
    "     'MOVIE_102817': Doctag(offset=13, word_count=386768, doc_count=26021),\n",
    "     'MOVIE_102824': Doctag(offset=103, word_count=227555, doc_count=13078),\n",
    "     'MOVIE_102875': Doctag(offset=54, word_count=659849, doc_count=40894),\n",
    "     ...\n",
    "     }\n",
    "     \n",
    "위 예시에서 영화 id 100647의 row id는 offset=153, 153번 입니다. docvecs.doctags으로부터 아래의 코드를 실행하면 row 별 영화 이름을 얻을 수 있습니다. \n",
    " \n",
    "작업의 각 부분들의 내용을 확인하기 위해 step 별로 list의 3개의 값을 출력하였습니다. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict.items()를 하면 (key,value)의 list가 만들어집니다\n",
      "[('MOVIE_72523', Doctag(offset=0, word_count=94513, doc_count=10187)), ('MOVIE_59845', Doctag(offset=1, word_count=144494, doc_count=13095)), ('MOVIE_109753', Doctag(offset=2, word_count=202367, doc_count=10361))] \n",
      "\n",
      "row[0]에 의해 key들의 list가 만들어지고, str인 key를 _로 split한 뒤 [1]을 가져왔기 때문에 영화 id가 str 형식으로 만들어집니다\n",
      "['72523', '59845', '109753'] \n",
      "\n",
      "id2movie를 이용하여 str 형식의 영화 id를 영화 이름으로 바꿉니다\n",
      "['고사 두 번째 이야기: 교생실습', '박쥐', '해무'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "row2movie = sorted(doc2vec_model.docvecs.doctags.items(), key=lambda x:x[1].offset)\n",
    "print('dict.items()를 하면 (key,value)의 list가 만들어집니다')\n",
    "print(row2movie[:3], '\\n')\n",
    "\n",
    "row2movie = [row[0].split('_')[1] for row in row2movie]\n",
    "print('row[0]에 의해 key들의 list가 만들어지고, str인 key를 _로 split한 뒤 [1]을 가져왔기 때문에 영화 id가 str 형식으로 만들어집니다')\n",
    "print(row2movie[:3], '\\n')\n",
    "\n",
    "row2movie = [id2movie.get(row, None) for row in row2movie]\n",
    "print('id2movie를 이용하여 str 형식의 영화 id를 영화 이름으로 바꿉니다')\n",
    "print(row2movie[:3], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    KMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto')\n",
    "    \n",
    "k-means의 parameter는 위와 같습니다. \n",
    "\n",
    "- k의 값은 n_clusters입니다. \n",
    "- n_init은 반복 횟수이므로 1로 바꾸겠습니다. \n",
    "- 일반적으로 k-means는 엄청 큰 데이터라 하여도 10번, 혹은 수십번이면 거의 수렴합니다. \n",
    "- max_iter 역시 작은 숫자로 바꿔서 실행하시는게 좋습니다. \n",
    "- n_jobs는 multi-processing을 하기 위한 processor의 개수입니다. 수업 서버에서는 그대로 1을, 개인 작업 시에는 이용하고픈 processor의 개수를 입력합니다. \n",
    "- verbose = 1로 설정하면, 매 iteration마다 학습 상태가 출력됩니다. 속도를 측정할 때 용이합니다. \n",
    "\n",
    "또한, spherical k-means를 하기 위해서는 metrics='cosine'으로 바꿔야 하지만, k-means는 Euclidean을 기준으로 만들어졌습니다. 만약 spherical k-means를 하고 싶다면, (172, 300)의 행렬을 row normalize하여 unit vector로 만들기 바랍니다. \n",
    "\n",
    "우리는 172개의 영화를 10개의 그룹으로 만들어 보겠습니다. 172개를 10개로 나누는 것은 그리 어려운 작업은 아닌가봅니다. 그래서 max_iter=10이었지만, 실제 iteration은 그 전에 끝남을 볼 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "movie_vectors = normalize(doc2vec_model.docvecs.doctag_syn0, axis=1, norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kmeans.fit_predict()\n",
      "Initialization complete\n",
      "Iteration  0, inertia 93.765\n",
      "Iteration  1, inertia 59.825\n",
      "Iteration  2, inertia 57.834\n",
      "Iteration  3, inertia 56.870\n",
      "Iteration  4, inertia 56.752\n",
      "Iteration  5, inertia 56.704\n",
      "Iteration  6, inertia 56.677\n",
      "Converged at iteration 6\n",
      "\n",
      "\n",
      "kmeans.fit_transform()\n",
      "Initialization complete\n",
      "Iteration  0, inertia 93.475\n",
      "Iteration  1, inertia 59.968\n",
      "Iteration  2, inertia 58.534\n",
      "Iteration  3, inertia 58.140\n",
      "Iteration  4, inertia 58.056\n",
      "Converged at iteration 4\n",
      "CPU times: user 132 ms, sys: 176 ms, total: 308 ms\n",
      "Wall time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=10, max_iter=10, n_init=1, verbose=1)\n",
    "print('kmeans.fit_predict()')\n",
    "clusters = kmeans.fit_predict(movie_vectors)\n",
    "\n",
    "print('\\n\\nkmeans.fit_transform()')\n",
    "distance = kmeans.fit_transform(movie_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans는 .fit_predict()와 .fit_transform() 두 가지 함수가 있습니다. \n",
    "\n",
    "    kmeans.fit_predict(doc2vec_model.docvecs.doctag_syn0)\n",
    "    \n",
    "fit_predict는 각 row의 label을 하나로 출력해줍니다. \n",
    "\n",
    "    kmeans.fit_transform(doc2vec_model.docvecs.doctag_syn0)\n",
    "    \n",
    "fit_transform은 각 row 별로 k 개의 centroid와의 거리를 출력해줍니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 4, 3, 6, 9, 6, 7, 7, 8, 6, 6, 7, 9, 7, 1, 3, 4, 1, 9, 1, 5, 5, 2,\n",
       "       2, 5, 2, 4, 3, 0, 5, 1, 9, 0, 2, 0, 7, 6, 5, 4, 2, 3, 4, 4, 2, 1, 7,\n",
       "       5, 1, 8, 5, 8, 2, 9, 7, 2, 1, 7, 4, 1, 5, 6, 4, 6, 0, 7, 8, 1, 0, 0,\n",
       "       5, 8, 7, 0, 5, 3, 9, 2, 1, 9, 1, 4, 7, 1, 6, 2, 0, 6, 7, 0, 6, 9, 6,\n",
       "       2, 0, 1, 7, 1, 5, 1, 2, 1, 0, 1, 3, 0, 8, 6, 1, 5, 8, 4, 2, 3, 6, 0,\n",
       "       1, 7, 5, 5, 6, 5, 6, 9, 8, 5, 9, 5, 1, 2, 4, 6, 0, 0, 5, 1, 7, 1, 5,\n",
       "       8, 2, 0, 6, 7, 4, 0, 5, 7, 0, 4, 2, 7, 1, 5, 2, 3, 1, 9, 5, 9, 4, 8,\n",
       "       8, 1, 6, 1, 1, 1, 5, 9, 2, 1, 9], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.89482378,  1.00731586,  0.74531107, ...,  0.82845932,\n",
       "         0.79268798,  1.02006966],\n",
       "       [ 0.89232999,  0.84914317,  0.9146802 , ...,  0.94406952,\n",
       "         0.74771188,  0.99522973],\n",
       "       [ 0.74894126,  1.1274449 ,  1.13702065, ...,  0.95307312,\n",
       "         0.61719052,  1.17676467],\n",
       "       ..., \n",
       "       [ 0.71324029,  1.06601743,  1.18711702, ...,  1.10404612,\n",
       "         0.86508808,  1.18010884],\n",
       "       [ 1.08668984,  0.98177112,  1.04005369, ...,  0.77653645,\n",
       "         1.04482512,  0.87507101],\n",
       "       [ 1.17354924,  0.63829647,  0.69452872, ...,  0.71914574,\n",
       "         1.03076123,  0.72523436]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 cluster label을 지니는 영화별로 그룹을 묶어서 이름을 확인해봅니다. 그 뒤, 각 label 별로 몇 개의 영화가 묶여 있는지 개수를 출력합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster # 0 has 18 moveis\n",
      "cluster # 1 has 29 moveis\n",
      "cluster # 2 has 18 moveis\n",
      "cluster # 3 has 8 moveis\n",
      "cluster # 4 has 14 moveis\n",
      "cluster # 5 has 23 moveis\n",
      "cluster # 6 has 19 moveis\n",
      "cluster # 7 has 18 moveis\n",
      "cluster # 8 has 11 moveis\n",
      "cluster # 9 has 14 moveis\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "cluster_to_row = defaultdict(lambda: [])\n",
    "for row_id, label in enumerate(clusters):\n",
    "    cluster_to_row[label].append(row_id)\n",
    "    \n",
    "cluster_to_row = dict(cluster_to_row)\n",
    "for label, rows in cluster_to_row.items():\n",
    "    print('cluster # %d has %d moveis' % (label, len(rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 cluster 별로 10개씩 영화의 이름을 출력하여, 군집화 결과가 어떤 느낌인지 확인해봅시다. 앞서 만들어둔 row2movie를 이용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cluster # 0\n",
      "  > 겨울왕국\n",
      "  > 타이타닉\n",
      "  > 지금, 만나러 갑니다\n",
      "  > 클레멘타인\n",
      "  > 인사이드 아웃\n",
      "  > 세 얼간이\n",
      "  > 비긴 어게인\n",
      "  > 레미제라블\n",
      "  > 어거스트 러쉬\n",
      "  > 하울의 움직이는 성\n",
      "\n",
      "cluster # 1\n",
      "  > 배트맨 대 슈퍼맨: 저스티스의 시작\n",
      "  > 메이즈 러너: 스코치 트라이얼\n",
      "  > 캡틴 아메리카: 시빌 워\n",
      "  > 빅 히어로\n",
      "  > 인디펜던스 데이: 리써전스\n",
      "  > 제이슨 본\n",
      "  > 쥬라기 월드\n",
      "  > 엑스맨: 데이즈 오브 퓨처 패스트\n",
      "  > 워크래프트: 전쟁의 서막\n",
      "  > 엣지 오브 투모로우\n",
      "\n",
      "cluster # 2\n",
      "  > 터널\n",
      "  > 영웅: 샐러멘더의 비밀\n",
      "  > 대호\n",
      "  > 26년\n",
      "  > 판도라\n",
      "  > 천안함 프로젝트\n",
      "  > 카트\n",
      "  > 국제시장\n",
      "  > 도가니\n",
      "  > 연평해전\n",
      "\n",
      "cluster # 3\n",
      "  > 해무\n",
      "  > 아가씨\n",
      "  > 곡성(哭聲)\n",
      "  > 검은 사제들\n",
      "  > 더 테러 라이브\n",
      "  > 숨바꼭질\n",
      "  > 부산행\n",
      "  > 설국열차\n",
      "\n",
      "cluster # 4\n",
      "  > 박쥐\n",
      "  > 내가 살인범이다\n",
      "  > 신세계\n",
      "  > 의형제\n",
      "  > 악마를 보았다\n",
      "  > 좋은 놈, 나쁜 놈, 이상한 놈\n",
      "  > 해바라기\n",
      "  > 최종병기 활\n",
      "  > 왕의 남자\n",
      "  > 아저씨\n",
      "\n",
      "cluster # 5\n",
      "  > 과속스캔들\n",
      "  > 미녀는 괴로워\n",
      "  > 응답하라 1988\n",
      "  > 완득이\n",
      "  > 인턴\n",
      "  > 광해, 왕이 된 남자\n",
      "  > 님아, 그 강을 건너지 마오\n",
      "  > 박수건달\n",
      "  > 형\n",
      "  > 두근두근 내 인생\n",
      "\n",
      "cluster # 6\n",
      "  > 고사 두 번째 이야기: 교생실습\n",
      "  > 해운대\n",
      "  > 국가대표\n",
      "  > 미스터 고\n",
      "  > 7광구\n",
      "  > 포화 속으로\n",
      "  > 감기\n",
      "  > 고지전\n",
      "  > 연가시\n",
      "  > 초능력자\n",
      "\n",
      "cluster # 7\n",
      "  > 도둑들\n",
      "  > 베를린\n",
      "  > 럭키\n",
      "  > 해적: 바다로 간 산적\n",
      "  > 암살\n",
      "  > 용의자\n",
      "  > 검사외전\n",
      "  > 관상\n",
      "  > 감시자들\n",
      "  > 역린\n",
      "\n",
      "cluster # 8\n",
      "  > 해리 포터와 죽음의 성물 - 2부\n",
      "  > 캐리비안의 해적 - 세상의 끝에서\n",
      "  > 트랜스포머 3\n",
      "  > 스카이라인\n",
      "  > 트와일라잇\n",
      "  > 나는 전설이다\n",
      "  > 해리 포터와 혼혈 왕자\n",
      "  > 트랜스포머: 패자의 역습\n",
      "  > 뉴 문\n",
      "  > 캐리비안의 해적 - 망자의 함\n",
      "\n",
      "cluster # 9\n",
      "  > 인터스텔라\n",
      "  > 다크 나이트 라이즈\n",
      "  > 다크 나이트\n",
      "  > 인셉션\n",
      "  > 배틀쉽\n",
      "  > 2012\n",
      "  > 맨 오브 스틸\n",
      "  > 그래비티\n",
      "  > 리얼 스틸\n",
      "  > 아이언맨\n"
     ]
    }
   ],
   "source": [
    "for label, rows in cluster_to_row.items():\n",
    "    print('\\ncluster # %d' % label)\n",
    "    for row in rows[:10]:\n",
    "        print('  > %s' % row2movie[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kmeans의 KMeans.cluster_centers_ 는 각 centroid의 좌표입니다. \n",
    "\n",
    "Doc2Vec 임베딩 벡터의 크기가 100이고, 클러스터의 개수가 10이기 때문에 centers 행렬의 크기는 (10, 100)입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난 시간에 연습했던 t-SNE를 이용하여 10개의 영화 군집을 시각화 할 수도 있습니다. label로 각 군집의 id와 영화 2개의 이름을 함께 annotation 합니다. \n",
    "\n",
    "영화의 개수가 172개 뿐이고, 300차원이기 때문에 10개의 군집으로 묶었을 때, 군집의 centroids의 벡터값이 서로 비슷할 수 있습니다. 이는 시각화의 측면에서는 좋지 않은 영향을 줄 수 있습니다. 시각화는 비슷한 것의 거리는 작게, 비슷하지 않은 것의 거리는 크게 표현되어야 하기 때문입니다. 하지만 k-means의 centroid는 고차원 벡터들의 평균이기 때문입니다. order 이상의 의미가 없을 수 있습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "krfont = {'family' : 'nanumgothic', 'weight' : 'bold', 'size'   : 10}\n",
    "matplotlib.rc('font', **krfont)\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=2)\n",
    "y_tsne = tsne.fit_transform(kmeans.cluster_centers_)\n",
    "y_tsne = y_tsne*1000\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(y_tsne[:,0], y_tsne[:,1], color='yellow')\n",
    "for i in range(y_tsne.shape[0]):\n",
    "    one_sample = row2movie[cluster_to_row[i][0]]\n",
    "    two_sample = row2movie[cluster_to_row[i][1]]\n",
    "    plt.annotate('cluster %d \\n(%s\\n%s)' % (i, one_sample, two_sample), \n",
    "                 (y_tsne[i, 0], y_tsne[i, 1])\n",
    "                )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
